---
title: "PCR"
output: html_document
---




```{r}
if (!require(ISLR)){
  install.packages("ISLR")
  require(ISLR)
} else {
  require(ISLR)
}


names(Hitters)


dim(Hitters)

sum(is.na(Hitters$Salary))

Hitters <- na.omit(Hitters)

dim(Hitters)

sum(is.na(Hitters))

if (!require("leaps")){
  install.packages("leaps")
  require("leaps")
} else {
  require("leaps")
}

regfit.full <- regsubsets(Salary~., data = Hitters)

summary(regfit.full)

regfit.full <- regsubsets(Salary ~ ., data=Hitters, nvmax=19)
regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
reg.summary <- summary(regfit.full)

names(reg.summary)

reg.summary$rsq

par(mfrow=c(2,2))
plot(reg.summary$rss, xlab="Number of Variables ", ylab="RSS", type="l")
plot(reg.summary$adjr2, xlab="Number of Variables ", ylab="Adjusted RSq", type="l")

which.max(reg.summary$adjr2)
points(11, reg.summary$adjr2[11], col="red",cex=2,pch =20)
plot(reg.summary$cp ,xlab="Number of Variables ",ylab="Cp", type="l")
which.min(reg.summary$cp)
points (10,reg.summary$cp [10], col ="red",cex=2,pch =20)
which.min(reg.summary$bic)
plot(reg.summary$bic, xlab="Number of Variables ",ylab="BIC", type="l")
points (6,reg.summary$bic[6],col="red",cex=2,pch =20)

plot(regfit.full ,scale="r2")
plot(regfit.full ,scale="adjr2")
plot(regfit.full ,scale="Cp")
plot(regfit.full ,scale="bic")

coef(regfit.full ,6)

regfit.fwd=regsubsets(Salary ~ .,data=Hitters , nvmax=19, method ="forward")
summary(regfit.fwd)
regfit.bwd=regsubsets(Salary ~ .,data=Hitters , nvmax=19, method ="backward")
summary(regfit.bwd)

coef(regfit.full, 7)

coef(regfit.fwd, 7)

coef(regfit.bwd, 7)

set.seed(1)
train <- sample(c(TRUE ,FALSE), nrow(Hitters),rep=TRUE)
test <- (!train)

regfit.best <- regsubsets(Salary ~ .,data=Hitters[train ,], nvmax=19)

test.mat=model.matrix(Salary ~ .,data=Hitters [test ,])

val.errors <- rep(NA ,19)
for(i in 1:19){
  coefi=coef(regfit.best ,id=i)
  #6.5 Lab 1: Subset Selection Methods 249
  pred=test.mat[,names(coefi)]%*%coefi
  val.errors[i]=mean(( Hitters$Salary[test]-pred)^2)
}

val.errors

which.min(val.errors)

coef(regfit.best ,10)

predict.regsubsets <- function (object , newdata ,id ,...){
  form=as.formula (object$call [[2]])
  mat=model.matrix(form ,newdata )
  coefi=coef(object ,id=id)
  xvars=names(coefi)
  mat[,xvars]%*%coefi
}

regfit.best <- regsubsets (Salary ~ .,data=Hitters ,nvmax=19)
coef(regfit.best ,10)

k <- 10
set.seed(1)
folds <- sample (1:k,nrow(Hitters),replace=TRUE)
cv.errors <- matrix (NA, k, 19, dimnames = list(NULL , paste(1:19)))

for(j in 1:k){
  best.fit=regsubsets (Salary ~ .,data=Hitters [folds!=j,], nvmax=19)
  for(i in 1:19){
    pred=predict (best.fit ,Hitters [folds ==j,],id=i)
    cv.errors[j,i]= mean( ( Hitters$Salary[ folds==j]-pred)^2)
  }
}

mean.cv.errors <- apply(cv.errors ,2, mean)
mean.cv.errors

par(mfrow=c(1,1))
plot(mean.cv.errors, type="b")

reg.best <- regsubsets(Salary ~ .,data=Hitters , nvmax=19)
coef(reg.best ,11)

x <- model.matrix(Salary ~ .,Hitters )[,-1]
y <- Hitters$Salary

if(!require("glmnet")){
  install.packages("glmnet")
  require("glmnet")
} else {
  require("glmnet")
}

grid <- 10^seq(10, -2, length =100)
ridge.mod <- glmnet(x, y, alpha=0, lambda=grid)

dim(coef(ridge.mod))

coef(ridge.mod)[ ,50]

sqrt(sum(coef(ridge.mod)[-1,50]^2) )

ridge.mod$lambda[60]
coef(ridge.mod)[ ,60]

sqrt(sum(coef(ridge.mod)[-1,60]^2))

set.seed(1)
train=sample (1: nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]

ridge.mod <- glmnet(x = x[train ,], 
                    y = y[train], 
                    alpha = 0, 
                    lambda = grid, 
                    thresh =1e-12)
ridge.pred <- predict(ridge.mod ,s=4, newx=x[test ,])
mean((ridge.pred -y.test)^2)


ridge.pred <- predict(ridge.mod ,s=1e10 ,newx=x[test ,])
mean((ridge.pred -y.test)^2)

ridge.pred <- predict(object=ridge.mod, s=0, newx=x[test ,], exact=TRUE, x=x[train, ], y=y[train])

mean((ridge.pred - y.test)^2)
lm(y ~ x, subset=train)
predict(ridge.mod ,s=0, exact=T, x=x[train, ], y=y[train], type="coefficients")[1:20,]

set.seed(1)
cv.out <- cv.glmnet(x[train ,],y[ train],alpha=0)
plot(cv.out)
bestlam <- cv.out$lambda.min
bestlam

ridge.pred <- predict(ridge.mod, s=bestlam, newx=x[test ,])
mean((ridge.pred -y.test)^2)

out <- glmnet(x,y,alpha=0)
predict(out, type="coefficients", s=bestlam)[1:20,]

lasso.mod <- glmnet(x[train ,], y[ train], alpha=1, lambda=grid)
plot(lasso.mod)

set.seed(1)
cv.out <- cv.glmnet(x[train ,], y[ train], alpha=1)
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod ,s=bestlam ,newx=x[test ,])
mean((lasso.pred -y.test)^2)

out <- glmnet(x, y, alpha=1, lambda=grid)
lasso.coef <- predict (out ,type="coefficients",s= bestlam) [1:20,]
lasso.coef

lasso.coef[lasso.coef!=0]

if(!require("pls")){
  install.packages("pls")
  require("pls")
} else {
  require("pls")
}


```

**PCR (주성분 회귀 기법)**

처음 M개의 주성분을 구한 다음 이 주성분들을 최소제곱을 이용해 적합되는 선형회귀모델의 설명 변수로 사용하는 것이다. 

![](캡처18.PNG)


![](캡처19.PNG)


PCR(주성분 회귀)은 pls 라이브러리의 pcr()함수를 사용하여 수행할 수 있다.

pcr() 함수의 문법은 몇가지 추가적인 옵션외에는 lm()과 유사하다. 

scale = TRUE를 통해서 각 설명변수를 표준화한다. 

또한 validation="CV"로 설정하면 pcr()은 사용된 주성분의 수 M에 대한 10-fold 교차 검증 오차를 계산한다. 

그리고 적합 결과는 summary()함수를 통해 확인할 수 있다. 

```{r}
set.seed(1)
pcr.fit <- pcr(Salary ~ ., data=Hitters , subset=train ,scale=TRUE ,
            validation ="CV")
summary(pcr.fit)

validationplot(pcr.fit ,val.type="MSEP")

```


교차 검증 오차가 가장 낮은 것은 M=7개의 주성분이 사용된 경우이다. 

이것은 작은 수의 성분을 사용하는 모델이면 충분할 수 있다는 것을 시사한다. 


```{r}

pcr.pred <- predict(pcr.fit ,x[test ,],ncomp =7)
mean((pcr.pred -y.test)^2)

```

MSE를 계산을 하면 96556이다. 
이것을 통해서 확인 할 수 있는 것은 검정셋 MSE는 능형회귀와 lasso를 사용하여 얻은 결과와 유사하다. 


마지막으로 교차검증에 의해 선택된 주성분의 수 M=7을 사용하여 PCR을 전체 자료에 적합한다.

```{r}

pcr.fit <- pcr(y ~ x, scale=TRUE ,ncomp=7)
summary(pcr.fit)

```

즉, M=7을 사용하게 되면 설면 변수 내의 모든 분산 또는 정보의 92%를 얻을 수 있다라는 것과 반응변수의 설명된 정보의 양은 46%라는 것을 확인할 수 있다.


***PLS(부분최소제곱)***

PCR의 경우에는 X1,...,Xp를 가장 잘 나타내는 방향을 찾아내는 것이다. 그렇기에 Y가 주성분 방향을 결정하는데 이용되지 않는다. 

하지만 PLS는 반응변수 Y를 이용하여 원래 변수들을 잘 근사할 뿐만 아니라 반응 변수와 관련 있는 새로운 변수들을 식별한다고 할 수 있다. 

즉, PCR은 설명 변수에 초점을 맞췄다면 PLS는 반응변수와 설명변수 모두를 설명하는데 도움이 되는 방향을 찾고자 한다. 

![](캡처20.PNG)

그래서 위의 그림을 보면 PLS는 PCA와 비교하여 상대적으로 인구 차원의 단위 변화당 광고 차원의 변화가 적은 방향을 선택하였다. 

이것은 인구가 광고보다 더 반응변수에 더 크게 상관되어 있음을 시사하게 된다. 

또한 PLS의 방향은 PCA만큼 가깝게 설명 변수들을 적합하지 않지만 반응 변수를 더 잘 설명한다는 것을 볼 수 있다. 

실질적으로는 PLS는 PCR과 비교했을 때 특별한 잇점은 없고 PCR, PLS, 능형회귀 모두 비슷한 성능을 보인다.


R에서는 라이브러리 pls에 포함되어 있는 plsr()함수를 사용하여 부분최소제곱을 수행한다. 


```{r}
set.seed(1)
pls.fit <- plsr(Salary ~ ., data=Hitters , subset=train , scale=TRUE ,validation ="CV")
summary(pls.fit)

validationplot(pls.fit ,val.type="MSEP")

```

가장 낮은 교차검증 오차는 M=2개의 부분최소제곱방향이 사용된 경우에 발생한다.


```{r}

pls.pred <- predict(pls.fit, x[test ,], ncomp =2)
mean((pls.pred -y.test)^2)

```

검정 MSE는 능형회귀, lasso, 그리고 PCR을 사용하여 얻은 검정 MSE보다 약간 높기는 하지만 비슷한 수준이다. 

마지막으로는 M=2를 사용하여 전체 자료에 PLS를 수행한다. 

```{r}
pls.fit <- plsr(Salary ~ ., data=Hitters , scale=TRUE , ncomp=2)
summary(pls.fit)

```

PLS 적합의 두 성분이 설명하는 Salary  내 분산의 백분율은 46.40%로 7개의 주성분을 사용한 PCR 적합의 46.69%와 거의 비슷하다. 이러한 결과는 PCR은 설명 변수에서 설명되는 분산의 양만 최대로 하려고 하지만 PLS는 설명 변수와 반응 변수 둘다 분산을 설명하는 방향을 찾기 때문이다. 